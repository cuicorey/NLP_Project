{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T06:03:39.461816Z",
     "start_time": "2020-05-05T06:03:39.457830Z"
    }
   },
   "outputs": [],
   "source": [
    "#! python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T06:03:41.380225Z",
     "start_time": "2020-05-05T06:03:39.840254Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, codecs\n",
    "import jieba\n",
    "from collections import Counter\n",
    "import re\n",
    "import sys\n",
    "from xlutils.copy import copy \n",
    "from xlrd import open_workbook \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing \n",
    "\n",
    "def filter (s):\n",
    "    r1 = re.sub(r\"\\s{1,}\", \"\", s)\n",
    "    r2 = re.sub(\"[0-9\\□\\[\\`\\~\\!\\@\\#\\$\\^\\&\\*\\(\\)\\=\\|\\{\\}\\'\\:\\;\\'\\,\\[\\]\\.\\<\\>\\/\\?\\~\\！\\@\\#\\\\\\&\\*\\%\\（\\）\\、\\- \\- \\，\\。\\？\\！\\；\\：\\‘\\’\\“\\”\\{\\}\\【\\】\\￥\\=\\-\\——|《\\》\\`\\~]\",\n",
    "                \"\", r1)\n",
    "    r3 = re.sub(\"A-Za-z\", \"\",r2)\n",
    "    return r3\n",
    "\n",
    "def get_stop_list (path):\n",
    "    result=[]\n",
    "    with open (path,'r',  encoding='UTF-8') as f:\n",
    "        for line in f:\n",
    "            result.append (line.strip('\\n').split(','))\n",
    "    s_list = [i for item in result for i in item]\n",
    "    return s_list\n",
    "\n",
    "def delete_stop_words (seg, stop_list):\n",
    "    for i in seg:\n",
    "        if i in stop_list:\n",
    "            seg.remove(i)\n",
    "    return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word lists\n",
    "\n",
    "def get_disease_list(path):\n",
    "    with codecs.open (path, 'r', encoding='UTF-8') as f:\n",
    "        txt = f.read()\n",
    "        txt = re.sub(r\"\\s{1,}\", \"\", txt)\n",
    "    d_list, seg = get_words(txt)\n",
    "    del d_list[0]\n",
    "    return d_list\n",
    "\n",
    "def get_uncertain_list (path):\n",
    "    result = []\n",
    "    with open (path, 'r', encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            result.append (line.strip('\\n').split(','))\n",
    "    u_list = [i for item in result for i in item]\n",
    "    del u_list[0]\n",
    "    return u_list\n",
    "\n",
    "def get_positive_list (path):\n",
    "    result = []\n",
    "    with open (path, 'r', encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            result.append (line.strip('\\n').split(','))\n",
    "    p_list = [i for item in result for i in item]\n",
    "    del p_list[0]\n",
    "    return p_list\n",
    "\n",
    "def get_negative_list (path):\n",
    "    result = []\n",
    "    with open (path, 'r', encoding = 'UTF-8') as f:\n",
    "        for line in f:\n",
    "            result.append (line.strip('\\n').split(','))\n",
    "    n_list = [i for item in result for i in item]\n",
    "    del n_list[0]\n",
    "    return n_list\n",
    "\n",
    "def get_word_lists (d_path, u_path, p_path, n_path):\n",
    "    d_list = get_disease_list(d_path)\n",
    "    u_list = get_uncertain_list(u_path)\n",
    "    p_list = get_positive_list(p_path)\n",
    "    n_list = get_negative_list(n_path)\n",
    "    return d_list, u_list, p_list, n_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words segmentation\n",
    "\n",
    "def get_words(txt):\n",
    "    seg = jieba.cut(txt)\n",
    "    seg_list = list (seg)\n",
    "    return seg_list, seg\n",
    "\n",
    "def total_words(seg_list, top, name):\n",
    "    c = Counter()\n",
    "    for x in seg_list:\n",
    "        if len(x)>1 and x != '\\r\\n':\n",
    "            c[x] += 1\n",
    "    total = 0\n",
    "    for (k,v) in c.most_common(len(c)):\n",
    "        total = total + v\n",
    "        \n",
    "    #print (name, \"总计出现 \", len(c), \"个不同的词\\n\")\n",
    "    #print (\"总词数为\", total, \"\\n\")\n",
    "    #print ('常用词频度统计结果(前', top, ')')\n",
    "    #for (k,v) in c.most_common(top):\n",
    "        #print('%s%s %s  %d' % ('  '*(5-len(k)), k, '*'*10, v))\n",
    "    #print (\"\\n\")\n",
    "    #print (\"*\"*30)\n",
    "    #print (\"\\n\")\n",
    "    \n",
    "    return len(c), c, total\n",
    "\n",
    "def show_frequency (seg_list,top):\n",
    "    le, c, total = total_words (seg_list)\n",
    "    print (\"本文总计出现 \", le, \"个不同的词\\n\")\n",
    "    print (\"总词数为\", total, \"\\n\")\n",
    "    print ('常用词频度统计结果')\n",
    "    for (k,v) in c.most_common(top):\n",
    "        print('%s%s %s  %d' % ('  '*(5-len(k)), k, '*'*int(v/3), v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary augmentation\n",
    "\n",
    "def dic_augmentation (path_d, path_u, path_p, path_n):\n",
    "    jieba.load_userdict(path_d)\n",
    "    jieba.load_userdict(path_u)\n",
    "    jieba.load_userdict(path_p)\n",
    "    jieba.load_userdict(path_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation\n",
    "\n",
    "def get_d_exposure (seg_list, d_list, total):\n",
    "    d_index = []\n",
    "    d_total = 0\n",
    "    d_exposure = 0\n",
    "    for i in range(0, len(seg_list)):\n",
    "        if seg_list[i] in d_list:\n",
    "            #print(seg_list[i])\n",
    "            d_total = d_total + 1\n",
    "            d_index.append(i)\n",
    "    d_exposure = d_total / total\n",
    "    return d_total, d_exposure, d_index\n",
    "\n",
    "def get_d_risk (d_index, seg_list, d_list, u_list, ran, total):\n",
    "    d_risk_total = 0\n",
    "    d_risk = 0\n",
    "    for i in d_index:\n",
    "        for j in range (max(i-ran, 0), min(len(seg_list), i+ran+1)):\n",
    "            if seg_list[j] in u_list:\n",
    "                d_risk_total  = d_risk_total  + 1\n",
    "    d_risk = d_risk_total / total\n",
    "    return d_risk_total, d_risk\n",
    "\n",
    "def get_p_sentiment (d_index, seg_list, d_list, p_list, ran, total):\n",
    "    p_sentiment_total = 0\n",
    "    p_sentiment = 0\n",
    "    for i in d_index:\n",
    "        for j in range (max(i-ran, 0), min(len(seg_list), i+ran+1)):\n",
    "            if seg_list[j] in p_list:\n",
    "                p_sentiment_total  = p_sentiment_total  + 1\n",
    "    p_sentiment = p_sentiment_total / total\n",
    "    return p_sentiment_total, p_sentiment\n",
    "\n",
    "def get_n_sentiment (d_index, seg_list, d_list, n_list, ran, total):\n",
    "    n_sentiment_total = 0\n",
    "    n_sentiment = 0\n",
    "    for i in d_index:\n",
    "        for j in range (max(i-ran, 0), min(len(seg_list), i+ran+1)):\n",
    "            if seg_list[j] in n_list:\n",
    "                n_sentiment_total  = n_sentiment_total  + 1\n",
    "    n_sentiment = n_sentiment_total / total\n",
    "    return n_sentiment_total, n_sentiment\n",
    "\n",
    "def get_d_sentiment (p_sentiment_total, n_sentiment_total, total):\n",
    "    d_sentiment_total = p_sentiment_total - n_sentiment_total\n",
    "    d_sentiment = d_sentiment_total / total\n",
    "    return d_sentiment_total, d_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to .xls excel file\n",
    "\n",
    "def write_to_excel (path, start_row, name, words, total, d_exposure_total,\n",
    "                    d_exposure, d_risk_total, d_risk, p_sentiment_total, p_sentiment, n_sentiment_total, n_sentiment, d_sentiment_total,\n",
    "                    d_sentiment):\n",
    "    \n",
    "    rb = open_workbook (path)\n",
    "    r_sheet = rb.sheet_by_index(0)\n",
    "    wb = copy(rb)\n",
    "    w_sheet = wb.get_sheet(0)\n",
    "    \n",
    "    name_column = 1\n",
    "    words_column = 2\n",
    "    total_column = 3\n",
    "    exposure_total_column = 4\n",
    "    exposure_column = 5\n",
    "    risk_total_column = 6\n",
    "    risk_column = 7\n",
    "    p_sentiment_total_column = 8\n",
    "    p_sentiment_column = 9\n",
    "    n_sentiment_total_column = 10\n",
    "    n_sentiment_column = 11\n",
    "    sentiment_total_column = 12\n",
    "    sentiment_column = 13\n",
    "    \n",
    "    w_sheet.write(start_row, name_column, name)\n",
    "    w_sheet.write(start_row, words_column, words)\n",
    "    w_sheet.write(start_row, total_column, total)\n",
    "    w_sheet.write(start_row, exposure_total_column, d_exposure_total)\n",
    "    w_sheet.write(start_row, exposure_column, d_exposure)\n",
    "    w_sheet.write(start_row, risk_total_column, d_risk_total)\n",
    "    w_sheet.write(start_row, risk_column, d_risk)\n",
    "    w_sheet.write(start_row, p_sentiment_total_column, p_sentiment_total)\n",
    "    w_sheet.write(start_row, p_sentiment_column, p_sentiment)\n",
    "    w_sheet.write(start_row, n_sentiment_total_column, n_sentiment_total)\n",
    "    w_sheet.write(start_row, n_sentiment_column, n_sentiment)\n",
    "    w_sheet.write(start_row, sentiment_total_column, d_sentiment_total)\n",
    "    w_sheet.write(start_row, sentiment_column, d_sentiment)\n",
    "    \n",
    "    wb.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name processing\n",
    "\n",
    "def get_name (path):\n",
    "    tail = os.path.split(path)[1]\n",
    "    name = tail.split(\"_\")[1]\n",
    "    #name = tail\n",
    "    return tail, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary lists\n",
    "\n",
    "def load_lists ():\n",
    "    d_list, u_list, p_list, n_list = get_word_lists(\"D:\\\\Activities\\\\NLP_RA\\\\COVID.txt\",\n",
    "                                                    \"D:\\\\Activities\\\\NLP_RA\\\\Unc.txt\",\n",
    "                                                    \"D:\\\\Activities\\\\NLP_RA\\\\Pos.txt\",\n",
    "                                                    \"D:\\\\Activities\\\\NLP_RA\\\\Neg.txt\")\n",
    "    \n",
    "    s_list = get_stop_list(\"D:\\\\Activities\\\\NLP_RA\\\\Stopwords\\\\stopwords-master\\\\cn_stopwords.txt\")\n",
    "    \n",
    "    dic_augmentation (\"D:\\\\Activities\\\\NLP_RA\\\\COVID.txt\",\n",
    "                      \"D:\\\\Activities\\\\NLP_RA\\\\Unc.txt\",\n",
    "                      \"D:\\\\Activities\\\\NLP_RA\\\\Pos.txt\",\n",
    "                      \"D:\\\\Activities\\\\NLP_RA\\\\Neg.txt\")\n",
    "    \n",
    "    return d_list, u_list, p_list, n_list, s_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(path, start_row, excel_path, d_list, u_list, p_list, n_list, s_list):\n",
    "\n",
    "    tail, name = get_name(path)\n",
    "    \n",
    "    with codecs.open(path,'r', encoding = 'UTF-8') as f:\n",
    "        txt = f.read()\n",
    "        txt = filter (txt)\n",
    "        \n",
    "\n",
    "    seg_list, seg = get_words(txt)\n",
    "    seg_list = delete_stop_words(seg_list, s_list)\n",
    "    #print (seg_list)\n",
    "    \n",
    "    top = 10\n",
    "    \n",
    "    words, frequency, total = total_words(seg_list, top, name)\n",
    "    #show_frequency(frequency, 10)\n",
    "    \n",
    "    ran = 10\n",
    "    d_exposure_total, d_exposure, d_index = get_d_exposure (seg_list, d_list, total)\n",
    "    d_risk_total, d_risk = get_d_risk (d_index, seg_list, d_list, u_list, ran, total)\n",
    "    p_sentiment_total, p_sentiment = get_p_sentiment (d_index, seg_list, d_list, p_list, ran, total)\n",
    "    n_sentiment_total, n_sentiment = get_n_sentiment (d_index, seg_list, d_list, n_list, ran, total)\n",
    "    d_sentiment_total, d_sentiment = get_d_sentiment (p_sentiment_total, n_sentiment_total, total)\n",
    "    \n",
    "    \n",
    "    #start_row = 2\n",
    "    print (\"\\n\")\n",
    "    print (name, \" \", words, \" \", total, \" \", d_exposure_total, \" \",\n",
    "           d_exposure, \" \", d_risk_total, \" \", d_risk, \" \", p_sentiment_total, \" \", p_sentiment, \" \", \n",
    "           n_sentiment_total, \" \", n_sentiment, \" \", d_sentiment_total, \" \", d_sentiment)\n",
    "    \n",
    "    write_to_excel (excel_path, start_row, name, words, total, d_exposure_total,\n",
    "                    d_exposure, d_risk_total, d_risk, p_sentiment_total, p_sentiment, n_sentiment_total, n_sentiment, d_sentiment_total,\n",
    "                    d_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_name_path, file_name_list, excel_path):\n",
    "    d_list, u_list, p_list, n_list, s_list = load_lists()\n",
    "    try:\n",
    "        with tqdm (range(2, len(file_name_list) + 2), ncols = 80, desc = \"分析进度\") as t:\n",
    "            for i in t:\n",
    "                try:\n",
    "                    run(file_name_path + \"\\\\\" + file_name_list[i-2], i, excel_path, d_list, u_list, p_list, n_list, s_list)\n",
    "                except ZeroDivisionError:\n",
    "                    pass\n",
    "    except KeyboardInterrupt:\n",
    "        t.close()\n",
    "        raise\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    excel_path = \"E:\\\\NLP_Dataset\\\\2019年报\\\\轻工制造\\\\轻工制造_Results - 副本.xls\"\n",
    "    file_name_path = \"E:\\\\NLP_Dataset\\\\2019年报\\\\轻工制造\\\\轻工制造txt\"\n",
    "    file_name_list = os.listdir(file_name_path)\n",
    "    main (file_name_path, file_name_list, excel_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
